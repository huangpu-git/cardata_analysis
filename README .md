## 爬取二手车信息，并对二手车价格的相关分析与预测，评估
### 爬取数据

​	本项目用python爬虫框架Scrapy爬取了北京，上海，广州，深圳，杭州的二手车信息，近万条数据，存放在CSV的文件中。用Requet，xpath，正则表达式等技术获取筛选所需要的页面信息，并保存到csv的文件中。

 表格中用到的字段说明：

| 字段       | 内容               |
| ---------- | :----------------- |
| city       | 获取信息的地区     |
| brand      | 车的品牌           |
| title      | 显示的总的标题     |
| start_time | 上牌时间           |
| distance   | 行驶的公里数       |
| volumn     | 排量               |
| gear       | 手动挡/自动挡/电动 |
| tag        | 显示购买标签       |
| price      | 价格               |

爬虫代码保存在ershouche_58的文件夹中。

### 分析数据

​	下面对爬取的数据先进行数据的清洗，数据分析以及建模预测，我采用了python库中numpy、pandas对数据进行清洗，分析。用matplotlib、seaborn对数据进行可视化分析。最后用One-Hot编码对特征工程的处理，并用GBDT算法进行建模预测，最后用MSE、MAE、R2对模型进行评估。

数据的清洗

- 处理部分的缺失值，因为数据中有少量的缺失值，且对数据没有多大的影响，我选择了直接删除缺失值的处理方式；
- 数据存在的重复值，可能由于在爬取数据时，存在重复抓取的现象，存在重复项。删除重复项的处理方式；
- 数据中的类型有不适合数据分析用的类型，进行转换，譬如：start_time 切取年份，并转换成数值类型。方便后续的分析统计；
- 查看数据中是否存在异常值，以及对异常的处理。

数据的分析

- 对数据的中不同地区二手市场的情况的简单概况分析；

- 二手车市场中各个品牌的占比，分析出各个品牌的市场保有率情况；
- 二手车各个品牌价格top10的情况；
- 二手车品牌最多的价格的分布情况以及波动情况。

建模预测

- 特征工程的处理，用独热编码，增加数据的维度，来增加预测的精准度；
- 选择GBDT算法来建模训练；
- MSE、MAE、RMSE、R2 模型评估方法对模型进行评估。

在分析数据的代码保存在cardata_analysis文件中，用jupyter notebook，这种交互式的IDE，用起来简洁方便直观。